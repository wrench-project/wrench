#!/usr/bin/env python3
#
# Copyright (c) 2019-2021. The WRENCH Team.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#

import argparse
import logging
import os

logger = logging.getLogger(__name__)


def _configure_logging(debug):
    """
    Configure the application's logging.
    :param debug: whether debugging is enabled
    """
    if debug:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
    ch.setFormatter(formatter)
    logger.addHandler(ch)


def _create_subdirectories(project_dir):
    """
    Create the subdirectories for the project
    :param project_dir: project directory
    """
    logger.debug('Creating subdirectories structure')
    sub_dirs = ['CMakeModules', 'src', 'test', 'doc', 'build', 'data', 'data/platform-files']
    for sub_dir in sub_dirs:
        if not os.path.isdir(project_dir + '/' + sub_dir):
            os.mkdir(project_dir + '/' + sub_dir)
            logger.debug('  Created subdirectory: %s' % project_dir + '/' + sub_dir)


def _write_contents(filename, contents):
    """
    Write a list of strings to a file
    :param filename: name of the file
    :param contents: list of strings
    """
    with open(filename, 'w') as f:
        for line in contents:
            f.write(line + '\n')


def _add_header():
    return [
        '/**',
        ' * Copyright (c) 2020. <ADD YOUR HEADER INFORMATION>.',
        ' * Generated with the wrench-init.in tool.',
        ' *',
        ' * This program is free software: you can redistribute it and/or modify',
        ' * it under the terms of the GNU General Public License as published by',
        ' * the Free Software Foundation, either version 3 of the License, or',
        ' * (at your option) any later version.',
        ' */'
        ''
    ]


def _write_cmakelists(project_dir):
    """
    Write the CMakeLists.txt file
    :param project_dir: project directory
    """
    logger.debug('Writing CMakeLists.txt file')
    _write_contents(project_dir + '/CMakeLists.txt', [
        'cmake_minimum_required(VERSION 3.2)',
        'message(STATUS "Cmake version ${CMAKE_MAJOR_VERSION}.${CMAKE_MINOR_VERSION}.${CMAKE_PATCH_VERSION}")',
        '',
        'project(%s)',
        '',
        'add_definitions("-Wall -Wno-unused-variable -Wno-unused-private-field")',
        '',
        'set(CMAKE_CXX_STANDARD 14)',
        '',
        'set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} "${CMAKE_SOURCE_DIR}/CMakeModules/")',
        '',
        'find_package(SimGrid REQUIRED)',
        'find_package(Boost REQUIRED)',
        '',
        '# include directories for dependencies and WRENCH libraries',
        'include_directories(src/ ${SimGrid_INCLUDE_DIR}/include /usr/local/include /opt/local/include /usr/local/include/wrench ${Boost_INCLUDE_DIR})',
        '',
        '# source files',
        'set(SOURCE_FILES',
        '       src/SimpleWMS.h',
        '       src/SimpleWMS.cpp',
        '       src/SimpleStandardJobScheduler.h',
        '       src/SimpleStandardJobScheduler.cpp',
        '       src/SimpleSimulator.cpp',
        '       )',
        '',
        '# test files',
        'set(TEST_FILES',
        '       )',
        '',
        '# wrench library and dependencies',
        'find_library(WRENCH_LIBRARY NAMES wrench)',
        'find_library(WRENCH_WORKFLOW_PARSER_LIBRARY NAMES wrenchwfcommonsworkflowparser)',
        'find_library(PUGIXML_LIBRARY NAMES pugixml)',
        'find_library(GTEST_LIBRARY NAMES gtest)',
        '',
        '# generating the executable',
        'add_executable(my-executable ${SOURCE_FILES})',
        '',
        'if (ENABLE_BATSCHED)',
        'target_link_libraries(my-executable',
        '                       ${WRENCH_LIBRARY}',
        '                       ${WRENCH_WORKFLOW_PARSER_LIBRARY}',
        '                       ${SimGrid_LIBRARY}',
        '                       ${PUGIXML_LIBRARY}',
        '                      -lzmq )',
        'else()',
        'target_link_libraries(my-executable',
        '                       ${WRENCH_LIBRARY}',
        '                       ${WRENCH_WORKFLOW_PARSER_LIBRARY}',
        '                       ${SimGrid_LIBRARY}',
        '                       ${PUGIXML_LIBRARY}',
        '                      )',
        'endif()',
        '',
        'install(TARGETS my-executable DESTINATION bin)',
        '',
        '# generating unit tests',
        'add_executable(unit_tests EXCLUDE_FROM_ALL',
        '                   ${SOURCE_FILES}',
        '                   ${TEST_FILES}',
        '               )',
        'target_link_libraries(unit_tests',
        '                       ${GTEST_LIBRARY} wrench -lpthread -lm',
        '                      )'
    ])


def _write_findsimgridcmake(project_sub_dir):
    """
    Write the FindSimGrid.cmake file
    :param project_sub_dir: target project sub-directory
    """
    logger.debug('Writing FindSimGrid.cmake file')
    """
    The file below is just a cut-and-paste of the FindSimGrid.cmake
    file (which is at the root of the SimGrid distribution, but also included into the
    WRENCH distribution). This is thus an awful
    cut and paste of that file, but it's not clear how to do this better. One option
    is to download the file from the simgrid master, but then, that may be a different version/.
    Another option is to copy the file from the wrench local distribution, but it's not clear
    where that is and/or if it's anywhere locally (e.g., the source could have been deleted
    after a make install).  Yet another option is to, during the WRENCH install, to copy that
    file somewhere, so that we know where it is. That seems a bit strange  (but perhaps to some
    place like /var/lib/wrench/?)
    """
    _write_contents(project_sub_dir + '/FindSimGrid.cmake',
                    """
                    TO_REPLACE_FIND_SIMGRID_CMAKE_END_TO_REPLACE
                    """.split('\n')
                    )


def _write_main(project_dir, compute_service):
    """
    Write the SimpleSimulator.cpp file
    :param project_dir:
    :param compute_service:
    """
    file_contents = _add_header()
    file_contents.extend([
        '#include <wrench.h>',
        '#include "SimpleStandardJobScheduler.h"',
        '#include "SimpleWMS.h"',
        '',
        'static bool ends_with(const std::string& str, const std::string& suffix) {',
        '  return str.size() >= suffix.size() && 0 == str.compare(str.size()-suffix.size(), suffix.size(), suffix);',
        '}',
        '',
        'int main(int argc, char **argv) {',
        '',
        '  // Declaration of the top-level WRENCH simulation object',
        '  wrench::Simulation simulation;',
        '',
        '  // Initialization of the simulation',
        '  simulation.init(&argc, argv);',
        '',
        '  // Parsing of the command-line arguments for this WRENCH simulation',
        '  if (argc != 3) {',
        '    std::cerr << "Usage: " << argv[0] << " <xml platform file> <workflow file>" << std::endl;',
        '    exit(1);',
        '  }',
        '',
        '  // The first argument is the platform description file, written in XML following the SimGrid-defined DTD',
        '  char *platform_file = argv[1];',
        '  // The second argument is the workflow description file, written in JSON using the WfCommons::WfFormat format',
        '  char *workflow_file = argv[2];',
        '',
        '  // Reading and parsing the workflow description file to create a wrench::Workflow object',
        '  std::cerr << "Loading workflow..." << std::endl;',
        '  wrench::Workflow *workflow;',
        '',
        '  if (ends_with(workflow_file,"json")) {',
        '    workflow = wrench::WfCommonsWorkflowParser::createWorkflowFromJSON(workflow_file, "1000Gf");',
        '  } else {',
        '    std::cerr << "Workflow file name must end with \'.json\'" << std::endl;',
        '    exit(1);',
        '  }',
        '  std::cerr << "The workflow has " << workflow->getNumberOfTasks() << " tasks " << std::endl;',
        '',
        '  // Reading and parsing the platform description file to instantiate a simulated platform',
        '  std::cerr << "Instantiating SimGrid platform..." << std::endl;',
        '  simulation.instantiatePlatform(platform_file);',
        '',
        '  // Get a vector of all the hosts in the simulated platform',
        '  std::vector<std::string> hostname_list = simulation.getHostnameList();',
        '',
        '  // Instantiate a storage service',
        '  std::string storage_host = hostname_list[(hostname_list.size() > 2) ? 2 : 1];',
        '  std::cerr << "Instantiating a SimpleStorageService on " << storage_host << "..." << std::endl;',
        '  auto storage_service = simulation.add(new wrench::SimpleStorageService(storage_host, {"/"}));',
        '',
        '  // Construct a list of hosts (in this example only one host)',
        '  std::string executor_host = hostname_list[(hostname_list.size() > 1) ? 1 : 0];',
        '  std::vector<std::string> execution_hosts = {executor_host};',
        '',
        '  // Create a list of storage services that will be used by the WMS',
        '  std::set<std::shared_ptr<wrench::StorageService>> storage_services;',
        '  storage_services.insert(storage_service);',
        '',
        '  // Create a list of compute services that will be used by the WMS',
        '  std::set<std::shared_ptr<wrench::ComputeService>> compute_services;',
        '',
        '  std::string wms_host = hostname_list[0];'
    ])

    if compute_service == 'cloud':
        file_contents.extend([
            '  // Instantiate a cloud service and add it to the simulation',
            '  try {',
            '    auto cloud_service = new wrench::CloudComputeService(',
            '          wms_host, execution_hosts, "", {},',
            '          {{wrench::CloudComputeServiceMessagePayload::STOP_DAEMON_MESSAGE_PAYLOAD, 1024}});',
            '',
            '    compute_services.insert(simulation.add(cloud_service));',
            '  } catch (std::invalid_argument &e) {',
            '    std::cerr << "Error: " << e.what() << std::endl;',
            '    std::exit(1);',
            '  }',
            ''
        ])

    elif compute_service == 'batch':
        file_contents.extend([
            '  // Instantiate a batch service and add it to the simulation',
            '  try {',
            '    auto batch_service = new wrench::BatchComputeService(',
            '          wms_host, hostname_list, "", {},',
            '          {{wrench::BatchComputeServiceMessagePayload::STOP_DAEMON_MESSAGE_PAYLOAD, 2048}});',
            '',
            '    compute_services.insert(simulation.add(batch_service));',
            '  } catch (std::invalid_argument &e) {',
            '    std::cerr << "Error: " << e.what() << std::endl;',
            '    std::exit(1);',
            '  }',
            ''
        ])

    file_contents.extend([
        '  // Instantiate a WMS',
        '  auto wms = simulation.add(',
        '          new SimpleWMS(std::unique_ptr<SimpleStandardJobScheduler>(',
        '                  new SimpleStandardJobScheduler(storage_service)),',
        '                        nullptr, compute_services, storage_services, wms_host));',
        '  wms->addWorkflow(workflow);',
        '',
        '  // Instantiate a file registry service',
        '  std::string file_registry_service_host = hostname_list[(hostname_list.size() > 2) ? 1 : 0];',
        '  std::cerr << "Instantiating a FileRegistryService on " << file_registry_service_host << "..." << std::endl;',
        '  auto file_registry_service =',
        '          new wrench::FileRegistryService(file_registry_service_host);',
        '  simulation.add(file_registry_service);',
        '',
        '  // It is necessary to store, or "stage", input files',
        '  std::cerr << "Staging input files..." << std::endl;',
        '  auto input_files = workflow->getInputFiles();',
        '  try {',
        '     for (auto const &f : input_files) {',
        '         simulation.stageFile(f, storage_service);',
        '     }',
        '  } catch (std::runtime_error &e) {',
        '    std::cerr << "Exception: " << e.what() << std::endl;',
        '    return 0;',
        '  }',
        '',
        '  // Launch the simulation',
        '  std::cerr << "Launching the Simulation..." << std::endl;',
        '  try {',
        '    simulation.launch();',
        '  } catch (std::runtime_error &e) {',
        '    std::cerr << "Exception: " << e.what() << std::endl;',
        '    return 0;',
        '  }',
        '  std::cerr << "Simulation done!" << std::endl;',
        '',
        '  return 0;',
        '}',
        '',
    ])

    logger.debug('Writing src/SimpleSimulator.cpp example file')
    _write_contents(project_dir + '/src/SimpleSimulator.cpp', file_contents)


def _write_simple_wms(project_dir):
    """
    Write the SimpleWMS.h and SimpleWMS.cpp files
    :param project_dir: project directory
    """
    logger.debug('Writing src/SimpleWMS.h example file')
    file_contents = _add_header()
    file_contents.extend([
        '#ifndef MY_SIMPLEWMS_H',
        '#define MY_SIMPLEWMS_H',
        '',
        '#include <wrench-dev.h>',
        '',
        'class Simulation;',
        '',
        '/**',
        ' *  @brief A simple WMS implementation',
        ' */',
        'class SimpleWMS : public wrench::WMS {',
        'public:',
        '    SimpleWMS(std::unique_ptr<wrench::StandardJobScheduler> standard_job_scheduler,',
        '              std::unique_ptr<wrench::PilotJobScheduler> pilot_job_scheduler,',
        '              const std::set<std::shared_ptr<wrench::ComputeService>> &compute_services,',
        '              const std::set<std::shared_ptr<wrench::StorageService>> &storage_services,',
        '              const std::string &hostname);',
        '',
        'private:',
        '    int main() override;',
        '',
        '    /** @brief The job manager */',
        '    std::shared_ptr<wrench::JobManager> job_manager;',
        '};',
        '',
        '#endif //MY_SIMPLEWMS_H',
        ''
    ])
    _write_contents(project_dir + '/src/SimpleWMS.h', file_contents)

    logger.debug('Writing src/SimpleWMS.cpp example file')
    file_contents = _add_header()
    file_contents.extend([
        '#include <iostream>',
        '',
        '#include "SimpleWMS.h"',
        '',
        'XBT_LOG_NEW_DEFAULT_CATEGORY(simple_wms, "Log category for Simple WMS");',
        '',
        '/**',
        ' * @brief Create a Simple WMS with a workflow instance, a scheduler implementation, and a list of compute services',
        ' */',
        'SimpleWMS::SimpleWMS(std::unique_ptr<wrench::StandardJobScheduler> standard_job_scheduler,',
        '                     std::unique_ptr<wrench::PilotJobScheduler> pilot_job_scheduler,',
        '                     const std::set<std::shared_ptr<wrench::ComputeService>> &compute_services,',
        '                     const std::set<std::shared_ptr<wrench::StorageService>> &storage_services,',
        '                     const std::string &hostname) : wrench::WMS(',
        '         std::move(standard_job_scheduler),',
        '         std::move(pilot_job_scheduler),',
        '         compute_services,',
        '         storage_services,',
        '         {}, nullptr,',
        '         hostname,',
        '         "simple") {}',
        '',
        '/**',
        ' * @brief main method of the SimpleWMS daemon',
        ' */',
        'int SimpleWMS::main() {',
        '',
        '  wrench::TerminalOutput::setThisProcessLoggingColor(wrench::TerminalOutput::COLOR_GREEN);',
        '',
        '  // Check whether the WMS has a deferred start time',
        '  checkDeferredStart();',
        '',
        '  WRENCH_INFO("About to execute a workflow with %lu tasks", this->getWorkflow()->getNumberOfTasks());',
        '',
        '  // Create a job manager',
        '  this->job_manager = this->createJobManager();',
        '',
        '  // Create a data movement manager',
        '  std::shared_ptr<wrench::DataMovementManager> data_movement_manager = this->createDataMovementManager();',
        '',
        '  while (true) {',
        '    // Get the ready tasks',
        '    std::vector<wrench::WorkflowTask *> ready_tasks = this->getWorkflow()->getReadyTasks();',
        '',
        '    // Get the available compute services',
        '    auto compute_services = this->getAvailableComputeServices<wrench::ComputeService>();',
        '',
        '    if (compute_services.empty()) {',
        '      WRENCH_INFO("Aborting - No compute services available!");',
        '      break;',
        '    }',
        '',
        '    // Run ready tasks with defined scheduler implementation',
        '    this->getStandardJobScheduler()->scheduleTasks(this->getAvailableComputeServices<wrench::ComputeService>(), ready_tasks);',
        '',
        '    // Wait for a workflow execution event, and process it',
        '    try {',
        '      this->waitForAndProcessNextEvent();',
        '    } catch (wrench::WorkflowExecutionException &e) {',
        '      WRENCH_INFO("Error while getting next execution event (%s)... ignoring and trying again",',
        '                   (e.getCause()->toString().c_str()));',
        '      continue;',
        '    }',
        '',
        '    if (this->getWorkflow()->isDone()) {',
        '      break;',
        '    }',
        '  }',
        '',
        '  wrench::Simulation::sleep(10);',
        '',
        '  this->job_manager.reset();',
        '',
        '  return 0;',
        '}'
    ])
    _write_contents(project_dir + '/src/SimpleWMS.cpp', file_contents)


def _write_simple_scheduler(project_dir, compute_service):
    """
    Write Scheduler files
    :param project_dir: project directory
    :param compute_service: compute service to which the scheduler will be generated
    """
    logger.debug('Writing src/SimpleStandardJobScheduler.h example file')
    file_contents = _add_header()
    file_contents.extend([
        '#ifndef MY_SIMPLESCHEDULER_H',
        '#define MY_SIMPLESCHEDULER_H',
        '',
        '#include <wrench-dev.h>',
        '',
        'class SimpleStandardJobScheduler : public wrench::StandardJobScheduler {',
        'public:',
        '  SimpleStandardJobScheduler(std::shared_ptr<wrench::StorageService> default_storage_service) :',
        '          default_storage_service(default_storage_service) {}',
        '',
        '  void scheduleTasks(const std::set<std::shared_ptr<wrench::ComputeService>> &compute_services,',
        '                     const std::vector<wrench::WorkflowTask *> &tasks);',
        '',
        'private:',
        '  std::shared_ptr<wrench::StorageService> default_storage_service;',
    ])

    if compute_service == 'cloud':
        file_contents.append(
            '  std::vector<std::shared_ptr<wrench::BareMetalComputeService>> compute_services_running_on_vms;')

    file_contents.extend([
        '};',
        '',
        '#endif //MY_SIMPLESCHEDULER_H',
        ''
    ])

    _write_contents(project_dir + '/src/SimpleStandardJobScheduler.h', file_contents)

    logger.debug('Writing src/SimpleStandardJobScheduler.cpp example file')
    file_contents = _add_header()
    file_contents.extend([
        '#include "SimpleStandardJobScheduler.h"',
        '',
        'XBT_LOG_NEW_DEFAULT_CATEGORY(simple_scheduler, "Log category for Simple Scheduler");',
        '',
        '/**',
        ' * @brief Schedule and run a set of ready tasks on available cloud resources',
        ' *',
        ' * @param compute_services: a set of compute services available to run jobs',
        ' * @param tasks: a map of (ready) workflow tasks',
        ' *',
        ' * @throw std::runtime_error',
        ' */',
        'void SimpleStandardJobScheduler::scheduleTasks(const std::set<std::shared_ptr<wrench::ComputeService>> &compute_services,',
        '                                               const std::vector<wrench::WorkflowTask *> &tasks) {',
        '',
        '  // Check that the right compute_services is passed',
        '  if (compute_services.size() != 1) {',
        '    throw std::runtime_error("This example Simple Scheduler requires a single compute service");',
        '  }',
        '',
        '  auto compute_service = *compute_services.begin();'
    ])

    if compute_service == 'cloud':
        file_contents.extend([
            'std::shared_ptr<wrench::CloudComputeService> cloud_service;',
            'if (not(cloud_service = std::dynamic_pointer_cast<wrench::CloudComputeService>(compute_service))) {',
            '    throw std::runtime_error("This example Cloud Scheduler can only handle a cloud service");',
            '}',
            'for (auto task : tasks) {',
            '',
            '   WRENCH_INFO("Trying to schedule ready task %s on a currently running VM", task->getID().c_str());',
            '',
            '   // Try to run the task on one of compute services running on previously created VMs',
            '   std::shared_ptr<wrench::BareMetalComputeService> picked_vm_cs = nullptr;',
            '   for (auto const &vm_cs : this->compute_services_running_on_vms) {',
            '       unsigned long num_idle_cores;',
            '       try {',
            '           num_idle_cores = vm_cs->getTotalNumIdleCores();',
            '       } catch (wrench::WorkflowExecutionException &e) {',
            '           // The service has some problem',
            '           throw std::runtime_error("Unable to get the number of idle cores: " + e.getCause()->toString());',
            '       }',
            '       if (task->getMinNumCores() <= num_idle_cores) {',
            '           picked_vm_cs = vm_cs;',
            '           break;'
            '       }',
            '   }',
            '',
            '   // If no current running compute service on a VM can accommodate the task, try',
            '   // to create a new one',
            '   if (picked_vm_cs == nullptr) {',
            '       WRENCH_INFO("No currently VM can support task %s, trying to create one...", task->getID().c_str());',
            '       unsigned long num_idle_cores;'
            '       try {',
            '           num_idle_cores = cloud_service->getTotalNumIdleCores();',
            '       } catch (wrench::WorkflowExecutionException &e) {',
            '           // The service has some problem',
            '           throw std::runtime_error("Unable to get the number of idle cores: " + e.getCause()->toString());'
            '       }',
            '       if (num_idle_cores >= task->getMinNumCores()) {',
            '           // Create and start the best VM possible for this task',
            '           try {',
            '               WRENCH_INFO("Creating a VM with %ld cores", std::min(task->getMinNumCores(), num_idle_cores));',
            '               auto vm = cloud_service->createVM(std::min(task->getMinNumCores(), num_idle_cores),',
            '                   task->getMemoryRequirement());',
            '               picked_vm_cs = cloud_service->startVM(vm);',
            '               this->compute_services_running_on_vms.push_back(picked_vm_cs);',
            '           } catch (wrench::WorkflowExecutionException &e) {',
            '               throw std::runtime_error("Unable to create/start a VM: " + e.getCause()->toString());',
            '           }',
            '       } else {',
            '           WRENCH_INFO("Not enough idle cores on the CloudComputeService to create a big enough VM for task %s", task->getID().c_str());',
            '       }',
            '   }',
            '',
            '   // If no VM is available to run the task, then nevermind',
            '   if (picked_vm_cs == nullptr) {',
            '       continue;',
            '   }',
            '',
            '   WRENCH_INFO("Submitting task %s for execution on a VM", task->getID().c_str());',
            '',
            '   // Submitting the task',
            '   std::map<wrench::WorkflowFile *, std::shared_ptr<wrench::FileLocation>> file_locations;',
            '   for (auto f : task->getInputFiles()) {',
            '       file_locations.insert(std::make_pair(f, wrench::FileLocation::LOCATION(default_storage_service)));',
            '   }',
            '   for (auto f : task->getOutputFiles()) {',
            '       file_locations.insert(std::make_pair(f, wrench::FileLocation::LOCATION(default_storage_service)));',
            '   }',
            '   auto job = this->getJobManager()->createStandardJob(task, file_locations);',
            '   this->getJobManager()->submitJob(job, picked_vm_cs);',
            '',
            '}'
        ])

    elif compute_service == 'batch':
        file_contents.extend([
            '  std::shared_ptr<wrench::BatchComputeService> batch_service;',
            '  if (not(batch_service = std::dynamic_pointer_cast<wrench::BatchComputeService>(compute_service))) {',
            '    throw std::runtime_error("This example Batch Scheduler can only handle a batch service");',
            '  }',
            '',
            '  WRENCH_INFO("There are %ld ready tasks to schedule", tasks.size());',
            '  for (auto task : tasks) {',
            '    std::map<wrench::WorkflowFile *, std::shared_ptr<wrench::FileLocation>> file_locations;',
            '    for (auto f : task->getInputFiles()) {',
            '      file_locations.insert(std::make_pair(f, wrench::FileLocation::LOCATION(default_storage_service)));',
            '    }',
            '    for (auto f : task->getOutputFiles()) {',
            '      file_locations.insert(std::make_pair(f, wrench::FileLocation::LOCATION(default_storage_service)));',
            '    }',
            '',
            '    auto job = this->getJobManager()->createStandardJob(task, file_locations);',
            '    std::map<std::string, std::string> batch_job_args;',
            '    batch_job_args["-N"] = "1";',
            '    batch_job_args["-t"] = "2000000"; //time in minutes',
            '    batch_job_args["-c"] = "1"; //number of cores per node',
            '    this->getJobManager()->submitJob(job, batch_service, batch_job_args);',
            '  }'
        ])

    file_contents.extend([
        '  WRENCH_INFO("Done with scheduling tasks as standard jobs");',
        '}',
        ''
    ])
    _write_contents(project_dir + '/src/SimpleStandardJobScheduler.cpp', file_contents)


def _write_platform(project_dir, compute_service):
    """
    Write platform example file
    :param project_dir: project directory
    :param compute_service: compute service to which the platform file will be generated
    """
    logger.debug('Writing data/platform-files/hosts.xml platform example file')
    file_contents = [
        '<?xml version="1.0"?>',
        '<!DOCTYPE platform SYSTEM "https://simgrid.org/simgrid.dtd">',
        '<platform version="4.1">',
        '    <zone id="AS0" routing="Full">'
    ]

    if compute_service == 'cloud':
        file_contents.extend([
            '        <host id="Tremblay" speed="1000Gf" core="1">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <host id="Jupiter" speed="1000Gf" core="1">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <host id="Fafard" speed="1000Gf" core="1">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <link id="1" bandwidth="125MBps" latency="100us"/>',
            '        <route src="Tremblay" dst="Jupiter">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Fafard" dst="Tremblay">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Fafard" dst="Jupiter">',
            '            <link_ctn id="1"/>',
            '        </route>'
        ])

    elif compute_service == 'batch':
        file_contents.extend([
            '        <host id="Host1" speed="1000Gf" core="10">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <host id="Host2" speed="1000Gf" core="10">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <host id="Host3" speed="1000Gf" core="10">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <host id="Host4" speed="1000Gf" core="10">',
            '          <disk id="large_disk1" read_bw="100MBps" write_bw="100MBps">',
            '             <prop id="size" value="30TB"/>',
            '             <prop id="mount" value="/"/>',
            '          </disk>',
            '        </host>',
            '        <link id="1" bandwidth="5000GBps" latency="0us"/>',
            '        <route src="Host1" dst="Host2">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Host1" dst="Host3">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Host1" dst="Host4">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Host2" dst="Host3">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Host2" dst="Host4">',
            '            <link_ctn id="1"/>',
            '        </route>',
            '        <route src="Host3" dst="Host4">',
            '            <link_ctn id="1"/>',
            '        </route>'
        ])

    file_contents.extend([
        '    </zone>',
        '</platform>'
    ])
    _write_contents(project_dir + '/data/platform-files/hosts.xml', file_contents)


def main():
    # Application's arguments
    parser = argparse.ArgumentParser(description='Create a skeleton for a WRENCH-based project.')
    parser.add_argument('project_dir', metavar='PROJECT_DIR', help='Project directory name')
    parser.add_argument('-c', '--compute_service', action='store', metavar='COMPUTE_SERVICE',
                        help='Specify a Compute Service (cloud or batch)', default='cloud')
    parser.add_argument('-d', '--debug', action='store_true', help='Print debug messages to stderr')
    parser.add_argument('-f', '--force', action='store_true',
                        help='Overwrites existing project directory (use sparingly)')
    args = parser.parse_args()

    # Configure logging
    _configure_logging(args.debug)

    # Sanity check
    if os.path.isdir(args.project_dir) and not args.force:
        logger.error('The provided project directory already exists:\n\t%s\nUse --force to overwrite the directory' \
                     % args.project_dir)
        exit(1)

    if args.compute_service:
        args.compute_service = args.compute_service.lower()
        if args.compute_service not in ['cloud', 'batch']:
            logger.error('Invalid Compute Service type: %s' % args.compute_service)
            exit(1)

    logger.info('Creating WRENCH skeleton project at: %s' % args.project_dir)

    if not os.path.isdir(args.project_dir):
        os.mkdir(args.project_dir)

    # subdirectories structure
    _create_subdirectories(args.project_dir)

    # write CMakeLists.txt
    _write_cmakelists(args.project_dir)

    # write CMakeModules/FindSimGrid.cmake
    _write_findsimgridcmake(args.project_dir + "/CMakeModules/")

    # create SimpleWMS
    _write_simple_wms(args.project_dir)

    # create SimpleScheduler
    _write_simple_scheduler(args.project_dir, args.compute_service)

    # create SimpleSimulator.cpp
    _write_main(args.project_dir, args.compute_service)

    # create platform example file
    _write_platform(args.project_dir, args.compute_service)

    logger.info('A WRENCH-based skeleton project with a "%s" compute service has been created at: %s' % (
        args.compute_service, args.project_dir))


if __name__ == '__main__':
    main()
